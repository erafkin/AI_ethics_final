{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "350ab075",
   "metadata": {},
   "source": [
    "in retrospect this obviously won't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6c05dbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "df_19 = pd.read_csv(\"../data/cv-corpus-19.0-delta-2024-09-13/en/validated.tsv\", delimiter=\"\\t\")\n",
    "df_21 = pd.read_csv(\"../data/cv-corpus-21.0-delta-2025-03-14/en/validated.tsv\", delimiter=\"\\t\")\n",
    "df_17 = pd.read_csv('../data/cv-corpus-17.0-delta-2024-03-15/en/validated.tsv', delimiter=\"\\t\")\n",
    "\n",
    "embeddings_19 = {}\n",
    "with open('../data/cv-corpus-19.0-delta-2024-09-13/commonvoice_embeddings.pkl', 'rb') as file:\n",
    "    embeddings_19 = pickle.load(file)\n",
    "embeddings_21 = {}\n",
    "with open('../data/cv-corpus-21.0-delta-2025-03-14/commonvoice_embeddings.pkl', 'rb') as file:\n",
    "    embeddings_21 = pickle.load(file)\n",
    "embeddings_17 = {}\n",
    "with open('../data/cv-corpus-17.0-delta-2024-03-15/commonvoice_embeddings.pkl', 'rb') as file:\n",
    "    embeddings_17 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a93427f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= []\n",
    "X_train= []\n",
    "for idx, gender in enumerate(df_21.gender.tolist()):\n",
    "    if gender in [\"male_masculine\", \"female_feminine\"]:\n",
    "        y_train.append(gender)\n",
    "        X_train.append(embeddings_21[df_21.path.tolist()[idx].split(\".\")[0]])\n",
    "for idx, gender in enumerate(df_17.gender.tolist()):\n",
    "    if gender in [\"male_masculine\", \"female_feminine\"]:\n",
    "        y_train.append(gender)\n",
    "        X_train.append(embeddings_17[df_17.path.tolist()[idx].split(\".\")[0]])\n",
    "# y_test= []\n",
    "# X_test= []\n",
    "for idx, gender in enumerate(df_19.gender.tolist()):\n",
    "    if gender in [\"male_masculine\", \"female_feminine\"]:\n",
    "        y_train.append(gender)\n",
    "        X_train.append(embeddings_19[df_19.path.tolist()[idx].split(\".\")[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cb751f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concept_erasure import LeaceEraser\n",
    "import torch\n",
    "eraser = LeaceEraser.fit(torch.tensor(X_train), torch.tensor([0  if y == \"female_feminine\" else 1 for y in y_train]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "625a4cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, Wav2Vec2ForCTC, Wav2Vec2CTCTokenizer\n",
    "\n",
    "model_checkpoint = \"facebook/wav2vec2-base-960h\"\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_checkpoint)\n",
    "processor = AutoProcessor.from_pretrained(model_checkpoint)\n",
    "tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "lm_head = model.lm_head\n",
    "vocab = processor.tokenizer.vocab.keys()\n",
    "\n",
    "embeddings_19 = {}\n",
    "with open('../data/cv_19.pkl', 'rb') as file:\n",
    "    embeddings_19 = pickle.load(file)\n",
    "# embeddings_21 = {}\n",
    "# with open('../data/cv_21.pkl', 'rb') as file:\n",
    "#     embeddings_21 = pickle.load(file)\n",
    "embeddings_17 = {}\n",
    "with open('../data/cv_17.pkl', 'rb') as file:\n",
    "    embeddings_17 = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "099daf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/var/folders/_l/m75yx49j3q98z5jct8l93xd40000gp/T/ipykernel_52634/2027004869.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  debiased_embedding = [eraser(torch.tensor(x)) for x in embedding[0]]\n",
      "4it [00:00, 13.02it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"log_softmax_lastdim_kernel_impl\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m truth \u001b[38;5;241m=\u001b[39m tokenizer(sentences[idx])\u001b[38;5;241m.\u001b[39minput_ids\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtruth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[1;32m     34\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# Zero the gradients from the previous iteration\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/AI_ethics_final/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AI_ethics_final/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/AI_ethics_final/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AI_ethics_final/venv/lib/python3.10/site-packages/torch/nn/functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"log_softmax_lastdim_kernel_impl\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from evaluate import load\n",
    "import re\n",
    "from tqdm import tqdm \n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "corpora = [17, 19]\n",
    "dfs = [df_17, df_19]\n",
    "embedding_dicts = [embeddings_17, embeddings_19]\n",
    "# Create a cross-entropy loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Choose an optimizer (e.g., SGD)\n",
    "optimizer = optim.Adam(lm_head.parameters(), lr=0.01)\n",
    "for df_idx, df in enumerate(dfs):\n",
    "    paths = df.path.to_list()\n",
    "    genders = df.gender.to_list()\n",
    "    sentences = df.sentence.to_list()\n",
    "    curr_dict = embedding_dicts[df_idx]\n",
    "    for idx, path in tqdm(enumerate(paths)):\n",
    "        if genders[idx] in [\"male_masculine\", \"female_feminine\"]:\n",
    "            embedding = curr_dict[path.split(\".\")[0]]\n",
    "            debiased_embedding = [eraser(torch.tensor(x)) for x in embedding[0]]\n",
    "            predictions = lm_head.forward(torch.stack(debiased_embedding))\n",
    "            predicted_ids = torch.argmax(predictions, dim=-1)\n",
    "            transcription = processor.batch_decode(predicted_ids)\n",
    "            prediction = transcription[0].lower()\n",
    "            prediction = tokenizer(prediction).input_ids\n",
    "            truth = tokenizer(sentences[idx]).input_ids\n",
    "            # Calculate loss\n",
    "            loss = criterion(torch.tensor(prediction), torch.tensor(truth))\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad() # Zero the gradients from the previous iteration\n",
    "            loss.backward()\n",
    "            # Update the weights and biases\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10860181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/var/folders/_l/m75yx49j3q98z5jct8l93xd40000gp/T/ipykernel_52634/595765433.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  debiased_embedding = [eraser(torch.tensor(x)) for x in embedding[0]]\n",
      "249it [04:31,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from evaluate import load\n",
    "import re\n",
    "from tqdm import tqdm \n",
    "import numpy as np\n",
    "# corpora = [17, 19, 21]\n",
    "# dfs = [df_17, df_19, df_21]\n",
    "# embedding_dicts = [embeddings_17, embeddings_19, embeddings_21]\n",
    "corpora = [21]\n",
    "dfs = [df_21]\n",
    "embedding_dicts = [embeddings_21]\n",
    "rows = []\n",
    "for df_idx, df in enumerate(dfs):\n",
    "    paths = df.path.to_list()\n",
    "    genders = df.gender.to_list()\n",
    "    sentences = df.sentence.to_list()\n",
    "    curr_dict = embedding_dicts[df_idx]\n",
    "    for idx, path in tqdm(enumerate(paths)):\n",
    "        if genders[idx] in [\"male_masculine\", \"female_feminine\"]:\n",
    "            embedding = curr_dict[path.split(\".\")[0]]\n",
    "            debiased_embedding = [eraser(torch.tensor(x)) for x in embedding[0]]\n",
    "            predictions = lm_head.forward(torch.stack(debiased_embedding))\n",
    "            predicted_ids = torch.argmax(predictions, dim=-1)\n",
    "            transcription = processor.batch_decode(predicted_ids)\n",
    "            truth = sentences[idx]\n",
    "            #clean\n",
    "            truth = re.sub(r'[^\\w\\s]', '', truth)\n",
    "            truth = truth.lower()\n",
    "            wer = load(\"wer\")\n",
    "            cer = load(\"cer\")\n",
    "            prediction = transcription[0].lower()\n",
    "            wer_score = wer.compute(predictions=[prediction], references=[truth])\n",
    "            cer_score = cer.compute(predictions=[prediction], references=[truth])\n",
    "            rows.append([path, genders[idx], prediction, truth, wer_score, cer_score, corpora[df_idx]])\n",
    "df = pd.DataFrame(rows, columns=[\"path\", \"gender\", \"prediction\", \"truth\", \"wer\", \"cer\", \"cv_corpus\"])\n",
    "df.to_csv(\"predictions_debiased.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff089cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count    42.0\n",
       " mean      1.0\n",
       " std       0.0\n",
       " min       1.0\n",
       " 25%       1.0\n",
       " 50%       1.0\n",
       " 75%       1.0\n",
       " max       1.0\n",
       " Name: wer, dtype: float64,\n",
       " count    42.000000\n",
       " mean      0.959243\n",
       " std       0.021865\n",
       " min       0.850000\n",
       " 25%       0.957294\n",
       " 50%       0.964901\n",
       " 75%       0.970149\n",
       " max       0.978723\n",
       " Name: cer, dtype: float64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_female = df[df[\"gender\"] == \"female_feminine\"]\n",
    "df_male = df[df[\"gender\"] == \"male_masculine\"]\n",
    "df_male.wer.describe(), df_male.cer.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66957a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count    143.0\n",
       " mean       1.0\n",
       " std        0.0\n",
       " min        1.0\n",
       " 25%        1.0\n",
       " 50%        1.0\n",
       " 75%        1.0\n",
       " max        1.0\n",
       " Name: wer, dtype: float64,\n",
       " count    143.000000\n",
       " mean       0.961026\n",
       " std        0.015491\n",
       " min        0.904762\n",
       " 25%        0.953125\n",
       " 50%        0.963636\n",
       " 75%        0.971831\n",
       " max        1.000000\n",
       " Name: cer, dtype: float64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_female.wer.describe(), df_female.cer.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
